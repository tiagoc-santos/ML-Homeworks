{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, matplotlib.pyplot as plt, numpy as np\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('parkinsons.csv')\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Train a Linear Regression model, an MLP Regressor with 2 hidden layers of 10 neurons each and no activation functions, and another MLP Regressor with 2 hidden layers of 10 neurons each using ReLU activation functions. (Use random_state=0 on the MLPs, regardless of the run). Plot a boxplot of the test MAE of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_linear = []\n",
    "mae_mlp_no_activation = []\n",
    "mae_mlp = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    linear = LinearRegression()\n",
    "    linear.fit(X_train, y_train)\n",
    "    y_pred_linear = linear.predict(X_test)\n",
    "    mae_linear.append(mean_absolute_error(y_test, y_pred_linear))\n",
    "    \n",
    "    # MLP Model no activation\n",
    "    mlp_no_activation = MLPRegressor(hidden_layer_sizes=(10,10), activation='identity', random_state=0)\n",
    "    mlp_no_activation.fit(X_train, y_train)\n",
    "    y_pred_mlp_no_activation = mlp_no_activation.predict(X_test)\n",
    "    mae_mlp_no_activation.append(mean_absolute_error(y_test, y_pred_mlp_no_activation))\n",
    "    \n",
    "    # MLP Model ReLU\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(10,10), activation='relu', random_state=0)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "    mae_mlp.append(mean_absolute_error(y_test, y_pred_mlp))\n",
    "    \n",
    "boxplot_data = [mae_linear, mae_mlp_no_activation, mae_mlp]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=boxplot_data)\n",
    "plt.xticks([0, 1, 2], ['Linear Regression', 'MLP No Activation', 'MLP ReLU'])\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('MAE comparison of 3 different models')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Compare a Linear Regression with a MLP with no activations, and explain the impact and the importance of using activation functions in a MLP.Support your reasoning with the results from the boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we analyze both the Linear Regression and the MLP with no activation boxplots, we notice them to be very similar to each other. \n",
    "\n",
    "This similarity makes sense if we consider the nature and calculus behind both models. The Linear Regression model is a simple model that captures linear relationships between the features and the target variable. On the other hand, the MLP model with no activation essentially is a more complex linear regression, despite having two hidden layers. Since there are no non-linear activation functions in the process, the model will not be able to catch other patterns or relationships in the data other than the linear ones, and so, the result will end up very similar, except with a lot of extra steps. Because of this, both models create two very similar MAE boxplots, as indicated in the first paragraph.\n",
    "\n",
    "We can finally understand the activation functions’ importance in introducing non-linearity to the model so that it can capture non-linear and more complex relationships between the features and, therefore, achieve a higher generalization capacity and better test results. Without them, MLP’s would just be linear transformations of the input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  Using a 80-20 train-test split with random_state=0, use a Grid Search to tune the hyperparameters of an MLP regressor with two hidden layers (size 10 each). The parameters to search over are: (i) L2 penalty, with the values $\\{0.0001, 0.001, 0.01\\}$; (ii) learning rate, with the values $\\{0.001, 0.01, 0.1\\}$; and (iii) batch size, with the values $\\{32, 64, 128\\}$. Plot the test MAE for each combination of hyperparameters, report the best combination, and discuss the trade-offs between the combinations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Grid Search parameters\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01], #L2 penalty\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1], #Learning rate  \n",
    "    'batch_size': [32, 64, 128]  #Batch size\n",
    "}\n",
    "\n",
    "# Create the MLP Regressor\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(10,10), random_state=0)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(mlp_regressor, param_grid=param_grid, \n",
    "                           scoring='neg_mean_absolute_error', cv = 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the best model\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Best hyperparameters found:\", \"\\nL2_penalty:\",grid_search.best_params_['alpha'], \"\\nLearning rate:\", grid_search.best_params_['learning_rate_init']\n",
    "      , \"\\nBatch size: \", grid_search.best_params_['batch_size'])\n",
    "print(\"Test MAE of the best model: \", test_mae)\n",
    "\n",
    "# Extract relevant columns\n",
    "params = results['params']\n",
    "mean_mae = -results['mean_test_score'] # MAE(since neg_mean_absolute_error is used)\n",
    "\n",
    "# Labels\n",
    "param_labels = [\n",
    "    f\"[{param['alpha']}, {param['learning_rate_init']}, {param['batch_size']}]\"\n",
    "    for param in params\n",
    "]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(mean_mae)), mean_mae, marker='o')\n",
    "plt.xticks(range(len(mean_mae)), param_labels, rotation=45, ha = 'right')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.xlabel('Hyperparameter Combinations')\n",
    "plt.title('MAE for each Hyperparameter Combination')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best combination of hyperparameters observed after this experience is:\n",
    "$${L2 penalty = 0.0001;\\hspace{0.1cm}Learning Rate = 0.01;\\hspace{0.1cm}Batch = 32}$$ \n",
    "\n",
    "As for the trade-offs of each hyperparameter:\n",
    "* **L2 penalty (alpha):**\n",
    "  \n",
    "    This parameter corresponds to the level of penalization to large coefficients we desire by applying Ridge’s regularization in our model. Higher values of alpha correspond to more regularization.\n",
    "    Therefore, we can associate overly lower values of this parameter with overfitting and low MAE scores in the test compared to the training, as low regularization is being applied, and excessively high levels with underfitting. The balance was found at alpha = 0.0001 in this model. \n",
    "\n",
    "* **Learning Rate:**\n",
    "\n",
    "    This parameter represents how big are the updates the model does to its weights and biases on each iteration.\n",
    "    Values too low might cause the model to take too much time to converge to the optimal solution while values too high might cause overshooting and divergence in the values.\n",
    "    This was the hyperparameter that had the most impact on the MAE scores with Learning Rate = 0.01 being the optimal value for this model.\n",
    "\n",
    "* **Batch:**\n",
    "\n",
    "    This parameter is the number of instances the model has in account before making the next update to the weights and biases.\n",
    "    Generally lower values will be always better for the model’s performance, since it means it is updating values more frequently. However they cause the training to take more time for the same reason, so the trade-off here is in balancing training time and effectiveness of the MLP.\n",
    "    As expected, the model had better MAE scores for the lower value of batch = 32.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
