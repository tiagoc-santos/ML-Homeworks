{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, matplotlib.pyplot as plt, numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = loadarff('diabetes.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) ANOVA is a statistical test that can be used to assess the discriminative power of asingle input variable. Using f_classif from sklearn, identify the input variables with the worst and best discriminative power. Plot their class-conditional probability density functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis = 1)\n",
    "df['Outcome'] = df['Outcome'].astype(int)\n",
    "y = df['Outcome']\n",
    "\n",
    "f_values, p_values = f_classif(X, y)\n",
    "\n",
    "# Identify the best and worst input variables based on f-values\n",
    "best = np.argmax(f_values)\n",
    "worst = np.argmin(f_values)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "print(f\"The input variables with the worst discriminative power is: {X.columns[worst]} and the best is: {X.columns[best]}\")\n",
    "\n",
    "# Best input variable\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(df[df['Outcome'] == 0][X.columns[best]], label= 'Normal', fill= True)\n",
    "sns.kdeplot(df[df['Outcome'] == 1][X.columns[best]], label= 'Diabetes', fill= True)\n",
    "plt.xlabel(f'{X.columns[best]}')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Class Conditional PDF for {X.columns[best]}')\n",
    "\n",
    "# Worst input variable\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(df[df['Outcome'] == 0][X.columns[worst]], label= 'Normal', fill= True)\n",
    "sns.kdeplot(df[df['Outcome'] == 1][X.columns[worst]], label= 'Diabetes', fill= True)\n",
    "plt.xlabel(f'{X.columns[worst]}')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Class Conditional PDF for {X.columns[worst]}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Using a stratified 80-20 training-testing split with a fixed seed (random_state=1), assess in a single plot both the training and testing accuracies of a decision tree with minimum sample split in {2,5,10,20,30,50,100} and the remaining parameters as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis = 1)\n",
    "df['Outcome'] = df['Outcome'].astype(int)\n",
    "y = df['Outcome']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "avg_train_accuracies, avg_test_accuracies = [], []\n",
    "min_sample_splits = [2,5,10,20,30,50,100]\n",
    "\n",
    "for min_sample_split in min_sample_splits:\n",
    "    train_acc_scores = []\n",
    "    test_acc_scores = []\n",
    "\n",
    "    # Run 10 times to improve accuracy\n",
    "    for i in range(10):\n",
    "        #Create a decision tree classifier\n",
    "        clf = DecisionTreeClassifier(min_samples_split= min_sample_split, random_state=1)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, clf.predict(x_train))\n",
    "        test_accuracy = accuracy_score(y_test, clf.predict(x_test))        \n",
    "        train_acc_scores.append(train_accuracy)\n",
    "        test_acc_scores.append(test_accuracy)\n",
    "        \n",
    "    avg_train_accuracies.append(np.mean(train_acc_scores))\n",
    "    avg_test_accuracies.append(np.mean(test_acc_scores))\n",
    "    \n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(min_sample_splits, avg_train_accuracies, label='Training Accuracy')\n",
    "plt.plot(min_sample_splits, avg_test_accuracies, label='Test Accuracy')\n",
    "plt.title('Decision Tree Accuracy vs. Min Sample Split')\n",
    "plt.xlabel('Min Sample Split')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Critically analyze these results, including the generalization capacity across settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better analysis, we can separate the results in two different ranges in the X axis (Min Sample Split). \n",
    "\n",
    "* Min Sample Split < ≈30\n",
    "\t\n",
    "\tThe train accuracy starts at 100% for a Min Sample Split of 2. That makes perfect sense as it means that we always split the decision tree whenever we get two different outcomes for differencing attribute values. This will inevitably result in a perfect classifying decision tree for every instance in the training data set, explaining the perfect accuracy score. However, it scores lower than 70% accuracy in unseen data (test data). \n",
    "\tAs the Min Sample Split setting increases along this range, the train accuracy decreases and the test accuracy increases due to a better generalization of the results.\n",
    "\tWe can come to the conclusion that the decision trees created from smaller Min Sample Split values suffer from overfitting. They become too complex, overly learning patterns and noise in the training data and then scoring poorly in the test data.\n",
    "\n",
    "* Min Sample Split > ≈30\n",
    "\t\t\n",
    "\tAs the setting for Min Sample Split values increase from 30, the test accuracy starts slowly decreasing along with the train accuracy. By this point the decision trees created are starting to become too simple, translating in worse accuracies for both data sets. They now indicate underfitting problems.\n",
    "\n",
    "The best balance between complexity and generalization capacity is found setting the Min Sample Split value at around 30, where the maximum test accuracy of about 77% is reached. At this point, the model catches enough patterns in the data to perform well with unseen data, without overly fitting the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) To deploy the predictor, a healthcare provider opted to learn a single decision tree (random_state=1) using all available data and ensuring that the maximum depth would be 3 in order to avoid overfitting risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> i. Plot the decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis = 1)\n",
    "df['Outcome'] = df['Outcome'].astype(int)\n",
    "y = df['Outcome']\n",
    "\n",
    "predictor = tree.DecisionTreeClassifier(random_state=1, max_depth=3)\n",
    "predictor.fit(X, y)\n",
    "\n",
    "feature_names = X.columns\n",
    "class_names = ['Normal', 'Diabetes']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "tree.plot_tree(predictor, feature_names=feature_names, class_names=class_names, impurity=False, filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ii.Explain what characterizes diabetes by identifying the conditional associations together with their posterior probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yapp caçador 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
